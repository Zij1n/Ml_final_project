{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IKHZts-TIPz"
      },
      "outputs": [],
      "source": [
        "from fastai.vision import *\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import pickle as pkl\n",
        "import torch\n",
        "from torchvision.utils import save_image\n",
        "from sklearn.model_selection import KFold\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
        "from torch.nn import functional as F\n",
        "import torchvision\n",
        "from torchvision import datasets,transforms\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import precision_score\n",
        "DATA_PATH=\"/content/lazydata/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sn7d7NbLUBdb",
        "outputId": "2828397a-7fe4-493f-97ac-021f4bf080df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Thu Dec 15 02:29:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  A100-SXM4-40GB      Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    50W / 400W |      0MiB / 40536MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.cuda.empty_cache() \n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6dlSDNIESwh",
        "outputId": "41ecabfc-c47c-492b-f745-6594963882ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/ml/testX.pt.zip\n",
            "replace /content/testX.pt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/ml/testX.pt.zip -d /content/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4RnlNcIV3LT",
        "outputId": "d26d7c75-2483-4862-a5ab-cca89011bac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/ml/lazydata-20221208T200112Z-001.zip\n",
            "replace /content/lazydata/test/X/561/field_id.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/ml/lazydata-20221208T200112Z-001.zip -d /content/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYTkFL6kTIP1"
      },
      "outputs": [],
      "source": [
        "class LazyLoadDataset(Dataset):\n",
        "    def trim(depth):\n",
        "        equalized = cv2.equalizeHist(depth)\n",
        "\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(equalized)\n",
        "\n",
        "        # Set the lower and upper thresholds for trimming\n",
        "        lower_threshold = min_val + 0.05 * (max_val - min_val)\n",
        "        upper_threshold = max_val - 0.05 * (max_val - min_val)\n",
        "\n",
        "        # Discard the top and bottom 5% of the data\n",
        "        trimmed = cv2.threshold(equalized, lower_threshold, upper_threshold, 0)\n",
        "\n",
        "        # Find the new minimum and maximum intensity values\n",
        "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(trimmed)\n",
        "\n",
        "        # Perform min-max normalization\n",
        "        normalized = cv2.normalize(trimmed, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)\n",
        "    def __init__(self,path,train=True,transform=None):\n",
        "        self.transform=transform\n",
        "        path=path+(\"train/\" if train else \"test/\")\n",
        "        \n",
        "        self.pathX=path+\"X/\"\n",
        "        self.pathY=path+\"Y/\"\n",
        "        \n",
        "        self.data=os.listdir(self.pathX)\n",
        "        \n",
        "    def __getitem__(self,idx):\n",
        "        f=self.data[idx]\n",
        "        \n",
        "        #X\n",
        "        #read rgb images\n",
        "        img0=cv2.imread(self.pathX+f+\"/rgb/0.png\")\n",
        "        img1=cv2.imread(self.pathX+f+\"/rgb/1.png\")\n",
        "        img2=cv2.imread(self.pathX+f+\"/rgb/2.png\")\n",
        "        if self.transform is not None:\n",
        "            img0=self.transform(Image.fromarray(img0))\n",
        "            img1=self.transform(Image.fromarray(img1))\n",
        "            img2=self.transform(Image.fromarray(img2))\n",
        "     \n",
        "        depth=np.load(self.pathX+f+\"/depth.npy\")\n",
        "      \n",
        "        field_id=pkl.load(open(self.pathX+f+\"/field_id.pkl\",\"rb\"))\n",
        "     \n",
        "        Y=np.load(self.pathY+f+\".npy\")\n",
        "        \n",
        "        return (img0,img1,img2,depth/1000,field_id),Y*1000\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dIi70HtTIP2"
      },
      "outputs": [],
      "source": [
        "def train(epoch, model, optimizer):\n",
        "    model.train()\n",
        "    losss=[]\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):#inside loop: shape of data is [64,224,224,9] target is [64,12]\n",
        "\n",
        "\n",
        "        RGBs=torch.stack((data[0][:,0,:,:],data[0][:,1,:,:],data[0][:,2,:,:],data[1][:,0,:,:],data[1][:,1,:,:],data[1][:,2,:,:],data[2][:,0,:,:],data[2][:,1,:,:],data[2][:,2,:,:]),1)\n",
        "        depth=data[3]\n",
        "        depth=(depth-min_d)/(max_d-min_d)\n",
        "        data=torch.cat((RGBs,depth), 1)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        output = model(data)\n",
        "        mse_loss = nn.MSELoss()\n",
        "        loss = mse_loss(output.float(), target.float())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losss.append(loss.item())\n",
        "    print(np.mean(losss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHbilRFrTIP2"
      },
      "outputs": [],
      "source": [
        "transforms_train = transforms.Compose([\n",
        "    transforms.ColorJitter(brightness=.3,contrast=0.3,hue=.3), \n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CBXxDVOCq3E"
      },
      "outputs": [],
      "source": [
        "def get_min_and_max_depth(data):\n",
        "  min_depth, max_depth = float(\"inf\"),0\n",
        "  for image, tmp in data:\n",
        "    img0, img1, img2, depth, field_id = image\n",
        "    single_min = np.mean(depth)\n",
        "    single_max = np.max(depth)\n",
        "    min_depth=single_min if single_min<min_depth else min_depth\n",
        "    max_depth=single_max if single_min>max_depth else max_depth\n",
        "  return min_depth, max_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J4ClH85TIP2"
      },
      "outputs": [],
      "source": [
        "tmp_data=LazyLoadDataset(DATA_PATH,True)\n",
        "min_d,max_d=get_min_and_max_depth(tmp_data)\n",
        "train_dataset=LazyLoadDataset(DATA_PATH,True, transforms_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFdE2jm_jzik",
        "outputId": "ac0b543d-2f7e-40f2-ab1b-3a1c5cf4b0ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.82528, 65.535)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(min_d,max_d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "hm1jfjiY8QzX",
        "outputId": "c5c8f08d-cdae-46e8-8df4-7d91148ac1d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7f7e71fd0580>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(train_dataset[121][0][3][0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri3ys29fTIP4",
        "outputId": "e4e2f1be-d2eb-47ef-9222-16c5f48557fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torchvision.models.resnet152(pretrained=True)   \n",
        "weight=model.conv1.weight.clone()\n",
        "model.conv1 = nn.Conv2d(12, 64, kernel_size=7)\n",
        "with torch.no_grad():\n",
        "    model.conv1.weight[:,:3]=weight\n",
        "    model.conv1.weight[:,3]=model.conv1.weight[:,0]\n",
        "num_features = model.fc.in_features    \n",
        "model.fc = nn.Linear(num_features, 12) \n",
        "model=nn.DataParallel(model)\n",
        "model.to(device)\n",
        "criterion = nn.MSELoss()  #(set loss function)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "#                                                    step_size=1,\n",
        "#                                                    gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "P5G1uejmTIP4",
        "outputId": "5dc3cd12-5ee0-4275-a794-da8c9cecb275"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()\n",
        "for epoch in range(0, 70):\n",
        "    train(epoch, model, optimizer)\n",
        "#     lr_scheduler.step()\n",
        "#     test(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5y7iEfuqGfY"
      },
      "outputs": [],
      "source": [
        "    # for batch_idx, (data, target) in enumerate(train_loader):#inside loop: shape of data is [64,224,224,9] target is [64,12]\n",
        "\n",
        "\n",
        "    #     RGBs=torch.stack((data[0][:,0,:,:],data[0][:,1,:,:],data[0][:,2,:,:],data[1][:,0,:,:],data[1][:,1,:,:],data[1][:,2,:,:],data[2][:,0,:,:],data[2][:,1,:,:],data[2][:,2,:,:]),1)\n",
        "    #     depth=data[3]\n",
        "    #     depth=(depth-min_d)/(max_d-min_d)\n",
        "    #     print(depth)\n",
        "    #     break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWM9EUbaQkdH"
      },
      "outputs": [],
      "source": [
        "open(\"/content/model\",\"w\")\n",
        "torch.save(model, \"/content/model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frpC4SMMR1Dg"
      },
      "outputs": [],
      "source": [
        "# model = torch.load(\"/content/model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tlwSEFDTIP4"
      },
      "outputs": [],
      "source": [
        "# class LazyLoadDataset_test(Dataset):\n",
        "#     def __init__(self,path,train=True,transform=None):\n",
        "#         self.transform=transform\n",
        "#         path=path+(\"test/\")\n",
        "        \n",
        "#         self.pathX=path+\"X/\"\n",
        "     \n",
        "        \n",
        "#         self.data=os.listdir(self.pathX)\n",
        "        \n",
        "#     def __getitem__(self,idx):\n",
        "#         f=self.data[idx]\n",
        "        \n",
        "#         #X\n",
        "#         #read rgb images\n",
        "#         img0=cv2.imread(self.pathX+f+\"/rgb/0.png\")\n",
        "#         img1=cv2.imread(self.pathX+f+\"/rgb/1.png\")\n",
        "#         img2=cv2.imread(self.pathX+f+\"/rgb/2.png\")\n",
        "#         if self.transform is not None:\n",
        "#             img0=self.transform(Image.fromarray(img0))\n",
        "#             img1=self.transform(Image.fromarray(img1))\n",
        "#             img2=self.transform(Image.fromarray(img2))\n",
        "#         #read image depth\n",
        "#         depth=np.load(self.pathX+f+\"/depth.npy\")\n",
        "#         #read field ID\n",
        "        \n",
        "#         field_id=pkl.load(open(self.pathX+f+\"/field_id.pkl\",\"rb\"))\n",
        "#         #Y\n",
        "       \n",
        "        \n",
        "# #         #normalize rgb 0-255\n",
        "# #         img0=cv2.normalize(img0, None, alpha=0, beta=1,\n",
        "# #                              norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "# #         img1=cv2.normalize(img1, None, alpha=0, beta=1,\n",
        "# #                              norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "# #         img2=cv2.normalize(img2, None, alpha=0, beta=1,\n",
        "# #                              norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "# #         depth=cv2.normalize(depth/1000, None, alpha=0, beta=1,\n",
        "# #                              norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
        "        \n",
        "#         return img0,img1,img2,depth/1000,field_id\n",
        "#     def __len__(self):\n",
        "#         return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uo2h243TIP4"
      },
      "outputs": [],
      "source": [
        "# transforms_test = transforms.Compose([\n",
        "# #     transforms.ColorJitter(brightness=.3,contrast=0.3,hue=.3), # data augmentation\n",
        "#     transforms.ToTensor(),\n",
        "#     # transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # normalization\n",
        "# ])\n",
        "# test_d=LazyLoadDataset_test(DATA_PATH,True, transforms_test)\n",
        "# test_loader = torch.utils.data.DataLoader(test_d, batch_size=1, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jav_46bgzYDO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mp0gJMHPTIP5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idO7RM27Uw93"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def normalize_tensor(tensor):\n",
        "    mean = tensor.mean()\n",
        "    std = tensor.std()\n",
        "    normalized_tensor = (tensor - mean) / std\n",
        "    normalized_tensor = 0.5 * (normalized_tensor / 0.5) + 0.5\n",
        "\n",
        "    return normalized_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHY4ltPITIP5"
      },
      "outputs": [],
      "source": [
        "# preds = []\n",
        "# file_ids=[]\n",
        "# for (data) in tqdm(test_loader):#inside loop: shape of data is [64,224,224,9] target is [64,12]\n",
        "#         # send to device\n",
        "#         #reshape data from [64,224,224,9] to [64,9,224,224]\n",
        "\n",
        "#         RGBs=torch.stack((data[0][:,0,:,:],data[0][:,1,:,:],data[0][:,2,:,:],\n",
        "#                           data[1][:,0,:,:],data[1][:,1,:,:],data[1][:,2,:,:],\n",
        "#                           data[2][:,0,:,:],data[2][:,1,:,:],data[2][:,2,:,:]),1)\n",
        "#         #concate depth\n",
        "#         inn=torch.cat((RGBs,data[3]), 1)\n",
        "        \n",
        "#         # data = data.to(device)\n",
        "\n",
        "#         output = model(inn)\n",
        "#         preds.append(output.cpu().detach().numpy())\n",
        "#         file_ids.append(data[-1][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVDd6ZHLTIP5",
        "outputId": "7d6e2c98-e3bb-4b99-bb5b-97be076157c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([849, 3, 224, 224])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = torch.load('/content/testX.pt')\n",
        "file_ids = test_data[-1]\n",
        "depth_data=test_data[1]/1000\n",
        "depth_data=(depth_data-min_d)/(max_d-min_d)\n",
        "rgb_data = test_data[0]\n",
        "rgb_data[:,0]=normalize_tensor(rgb_data[:,0])\n",
        "rgb_data[:,1]=normalize_tensor(rgb_data[:,1])\n",
        "rgb_data[:,2]=normalize_tensor(rgb_data[:,2])\n",
        "new_test=torch.cat((rgb_data[:,0],rgb_data[:,1],rgb_data[:,2],depth_data),dim=1)\n",
        "rgb_data[:,2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH9Yy2yJmKRk"
      },
      "outputs": [],
      "source": [
        "# aa=test_data[1]/1000\n",
        "# bb=(aa-min_d)/(max_d-min_d)\n",
        "# bb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsrzJhjZlT5y",
        "outputId": "0bce3457-9d01-4ecb-ab52-11def1653611"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          ...,\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0022,  0.0022,  0.0023],\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0022,  0.0022,  0.0022]],\n",
              "\n",
              "         [[ 0.0157, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0157, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0159, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008]],\n",
              "\n",
              "         [[ 0.0235,  0.0228,  0.0224,  ...,  0.0466,  0.0469,  0.0472],\n",
              "          [ 0.0232,  0.0227,  0.0224,  ...,  0.0465,  0.0466,  0.0468],\n",
              "          [ 0.0231,  0.0226,  0.0224,  ...,  0.0462,  0.0463,  0.0466],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0026,  0.0026,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0026,  0.0026,  0.0026,  ...,  0.0003,  0.0003,  0.0003]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0024],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0024],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0024,  0.0024],\n",
              "          ...,\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0022,  0.0022,  0.0022],\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0022,  0.0022,  0.0022],\n",
              "          [ 0.0019,  0.0019,  0.0020,  ...,  0.0022,  0.0022,  0.0022]],\n",
              "\n",
              "         [[-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [-0.0019,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0005],\n",
              "          [-0.0018,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0005],\n",
              "          [-0.0018,  0.0017,  0.0017,  ...,  0.0004,  0.0004,  0.0004]],\n",
              "\n",
              "         [[ 0.0273,  0.0276,  0.0276,  ...,  0.0483,  0.0483,  0.0483],\n",
              "          [ 0.0278,  0.0280,  0.0281,  ...,  0.0479,  0.0481,  0.0479],\n",
              "          [ 0.0282,  0.0283,  0.0282,  ...,  0.0477,  0.0478,  0.0478],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0021,  0.0021,  0.0022],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ..., -0.0128, -0.0128,  0.0022],\n",
              "          [ 0.0027,  0.0027,  0.0026,  ...,  0.0050,  0.0050, -0.0128]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          ...,\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0018,  0.0019,  0.0021,  ...,  0.0023,  0.0023,  0.0023]],\n",
              "\n",
              "         [[ 0.0142,  0.0142,  0.0143,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0140,  0.0142,  0.0143,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0143,  0.0146,  0.0147,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008]],\n",
              "\n",
              "         [[ 0.0228,  0.0225,  0.0224,  ...,  0.0472,  0.0474,  0.0477],\n",
              "          [ 0.0228,  0.0226,  0.0225,  ...,  0.0468,  0.0469,  0.0472],\n",
              "          [ 0.0228,  0.0226,  0.0225,  ...,  0.0463,  0.0465,  0.0468],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0026,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0026,  0.0026,  0.0026,  ...,  0.0003,  0.0003,  0.0003]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          ...,\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0022,  0.0023,  0.0023],\n",
              "          [ 0.0019,  0.0019,  0.0020,  ...,  0.0022,  0.0022,  0.0022],\n",
              "          [ 0.0018,  0.0019,  0.0019,  ...,  0.0022,  0.0022,  0.0022]],\n",
              "\n",
              "         [[-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [-0.0020,  0.0018,  0.0018,  ...,  0.0006,  0.0005,  0.0005],\n",
              "          [-0.0019,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0005],\n",
              "          [-0.0018,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0005]],\n",
              "\n",
              "         [[ 0.0229,  0.0228,  0.0228,  ...,  0.0479,  0.0481,  0.0483],\n",
              "          [ 0.0225,  0.0225,  0.0225,  ...,  0.0478,  0.0478,  0.0479],\n",
              "          [ 0.0224,  0.0224,  0.0223,  ...,  0.0474,  0.0475,  0.0477],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ..., -0.0128,  0.0021,  0.0022],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0050,  0.0051,  0.0051]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          ...,\n",
              "          [ 0.0021,  0.0021,  0.0022,  ...,  0.0022,  0.0022,  0.0023],\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0022,  0.0022,  0.0023],\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0022,  0.0022,  0.0023]],\n",
              "\n",
              "         [[ 0.0144,  0.0146,  0.0148,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0145,  0.0147,  0.0149,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [ 0.0145,  0.0148,  0.0152,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [ 0.0017,  0.0017,  0.0017,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0017,  ...,  0.0008,  0.0008,  0.0008],\n",
              "          [ 0.0017,  0.0017,  0.0018,  ...,  0.0008,  0.0008,  0.0008]],\n",
              "\n",
              "         [[ 0.0235,  0.0231,  0.0228,  ...,  0.0479,  0.0481,  0.0484],\n",
              "          [ 0.0237,  0.0232,  0.0228,  ...,  0.0477,  0.0479,  0.0479],\n",
              "          [ 0.0240,  0.0234,  0.0228,  ...,  0.0474,  0.0477,  0.0477],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0002,  0.0002,  0.0002]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0023,  0.0023,  0.0023,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          ...,\n",
              "          [ 0.0020,  0.0021,  0.0022,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0020,  0.0021,  0.0021,  ...,  0.0023,  0.0023,  0.0023],\n",
              "          [ 0.0019,  0.0020,  0.0021,  ...,  0.0023,  0.0023,  0.0023]],\n",
              "\n",
              "         [[-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          [-0.0128, -0.0128, -0.0128,  ..., -0.0128, -0.0128, -0.0128],\n",
              "          ...,\n",
              "          [-0.0019,  0.0017,  0.0017,  ...,  0.0006,  0.0005,  0.0005],\n",
              "          [-0.0018,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0005],\n",
              "          [-0.0018,  0.0017,  0.0017,  ...,  0.0005,  0.0005,  0.0004]],\n",
              "\n",
              "         [[ 0.0261,  0.0260,  0.0259,  ...,  0.0475,  0.0477,  0.0477],\n",
              "          [ 0.0260,  0.0259,  0.0258,  ...,  0.0468,  0.0469,  0.0471],\n",
              "          [ 0.0258,  0.0258,  0.0256,  ...,  0.0462,  0.0463,  0.0465],\n",
              "          ...,\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0021,  0.0021,  0.0022],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ..., -0.0128, -0.0128,  0.0022],\n",
              "          [ 0.0027,  0.0027,  0.0027,  ...,  0.0050,  0.0050, -0.0128]]]])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "depth_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU4NvLKoTIP5",
        "outputId": "c72042c5-5936-4e0c-c7e6-c313ba3600ca"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170/170 [00:07<00:00, 22.40it/s]\n"
          ]
        }
      ],
      "source": [
        "split_test=torch.split(new_test,5,dim=0)\n",
        "preds = []\n",
        "for data in tqdm(split_test):\n",
        "    # Please remember to modify this loop, input and output based on your model/architecture\n",
        "    output = model(data)\n",
        "    preds.append(output.cpu().detach().numpy()/1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibkBFsx1TIP6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfP8Bq_NTIP6",
        "outputId": "5bf9dfec-f94b-4f2c-9a27-7d80e4a3d90e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Written to csv file /content/out.csv\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "# model=model_cnn\n",
        "outfile = '/content/out.csv'\n",
        "\n",
        "output_file = open(outfile, 'w')\n",
        "\n",
        "titles = ['ID', 'FINGER_POS_1', 'FINGER_POS_2', 'FINGER_POS_3', 'FINGER_POS_4', 'FINGER_POS_5', 'FINGER_POS_6',\n",
        "         'FINGER_POS_7', 'FINGER_POS_8', 'FINGER_POS_9', 'FINGER_POS_10', 'FINGER_POS_11', 'FINGER_POS_12']\n",
        "\n",
        "# test_data = torch.load('/kaggle/input/csci-ua-473-intro-to-machine-learning-fall22/test/test/testX.pt')\n",
        "file_ids = test_data[-1]\n",
        "# depth_data=test_data[1]\n",
        "# rgb_data = test_data[0]\n",
        "# model.eval()\n",
        "# new_test=torch.cat((rgb_data[:,0],rgb_data[:,1],rgb_data[:,2],depth_data),dim=1)\n",
        "# split_test=torch.split(new_test,100,dim=0)\n",
        "# for data in split_test:\n",
        "#     # Please remember to modify this loop, input and output based on your model/architecture\n",
        "#     output = model(data.to('cuda'))\n",
        "#     preds.append(output[0].cpu().detach().numpy())\n",
        "\n",
        "df = pd.concat([pd.DataFrame(file_ids), pd.DataFrame.from_records(np.concatenate(preds))], axis = 1, names = titles)\n",
        "df.columns = titles\n",
        "df.to_csv(outfile, index = False)\n",
        "print(\"Written to csv file {}\".format(outfile))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "dL9EhdAo40si",
        "outputId": "f419dfb4-7033-4260-a8b9-9a5ac5af2706"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2ca816e4-79c4-4d71-af4b-0f538f18b7be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>FINGER_POS_1</th>\n",
              "      <th>FINGER_POS_2</th>\n",
              "      <th>FINGER_POS_3</th>\n",
              "      <th>FINGER_POS_4</th>\n",
              "      <th>FINGER_POS_5</th>\n",
              "      <th>FINGER_POS_6</th>\n",
              "      <th>FINGER_POS_7</th>\n",
              "      <th>FINGER_POS_8</th>\n",
              "      <th>FINGER_POS_9</th>\n",
              "      <th>FINGER_POS_10</th>\n",
              "      <th>FINGER_POS_11</th>\n",
              "      <th>FINGER_POS_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>146</td>\n",
              "      <td>0.049949</td>\n",
              "      <td>0.052382</td>\n",
              "      <td>0.120513</td>\n",
              "      <td>0.055146</td>\n",
              "      <td>0.000273</td>\n",
              "      <td>0.116482</td>\n",
              "      <td>0.067199</td>\n",
              "      <td>-0.053297</td>\n",
              "      <td>0.102544</td>\n",
              "      <td>0.050549</td>\n",
              "      <td>0.032086</td>\n",
              "      <td>-0.044161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1474</td>\n",
              "      <td>0.044438</td>\n",
              "      <td>0.053474</td>\n",
              "      <td>0.120828</td>\n",
              "      <td>0.037784</td>\n",
              "      <td>-0.000080</td>\n",
              "      <td>0.125113</td>\n",
              "      <td>0.037577</td>\n",
              "      <td>-0.056280</td>\n",
              "      <td>0.128869</td>\n",
              "      <td>0.053176</td>\n",
              "      <td>0.042141</td>\n",
              "      <td>-0.036849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>190</td>\n",
              "      <td>0.049199</td>\n",
              "      <td>0.052962</td>\n",
              "      <td>0.122678</td>\n",
              "      <td>0.082618</td>\n",
              "      <td>-0.002069</td>\n",
              "      <td>0.094010</td>\n",
              "      <td>0.045188</td>\n",
              "      <td>-0.040969</td>\n",
              "      <td>-0.017099</td>\n",
              "      <td>0.060214</td>\n",
              "      <td>0.038496</td>\n",
              "      <td>-0.039771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1544</td>\n",
              "      <td>0.047385</td>\n",
              "      <td>0.053092</td>\n",
              "      <td>0.112071</td>\n",
              "      <td>0.061520</td>\n",
              "      <td>-0.001804</td>\n",
              "      <td>0.101508</td>\n",
              "      <td>0.073931</td>\n",
              "      <td>-0.052448</td>\n",
              "      <td>0.097279</td>\n",
              "      <td>0.048981</td>\n",
              "      <td>0.050606</td>\n",
              "      <td>-0.026215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>952</td>\n",
              "      <td>0.057916</td>\n",
              "      <td>0.051814</td>\n",
              "      <td>0.110039</td>\n",
              "      <td>0.077338</td>\n",
              "      <td>-0.001631</td>\n",
              "      <td>0.095259</td>\n",
              "      <td>0.089907</td>\n",
              "      <td>-0.040567</td>\n",
              "      <td>0.027763</td>\n",
              "      <td>0.058488</td>\n",
              "      <td>0.052136</td>\n",
              "      <td>-0.021543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>844</th>\n",
              "      <td>2647</td>\n",
              "      <td>0.045396</td>\n",
              "      <td>0.054515</td>\n",
              "      <td>0.125953</td>\n",
              "      <td>0.070016</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>0.098490</td>\n",
              "      <td>0.075598</td>\n",
              "      <td>-0.044305</td>\n",
              "      <td>0.039550</td>\n",
              "      <td>0.051826</td>\n",
              "      <td>0.040719</td>\n",
              "      <td>-0.028590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>3970</td>\n",
              "      <td>0.045581</td>\n",
              "      <td>0.053086</td>\n",
              "      <td>0.121230</td>\n",
              "      <td>0.074780</td>\n",
              "      <td>0.000851</td>\n",
              "      <td>0.092464</td>\n",
              "      <td>0.070901</td>\n",
              "      <td>-0.046276</td>\n",
              "      <td>0.032689</td>\n",
              "      <td>0.056352</td>\n",
              "      <td>0.036889</td>\n",
              "      <td>-0.048131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>1597</td>\n",
              "      <td>0.053151</td>\n",
              "      <td>0.053440</td>\n",
              "      <td>0.120700</td>\n",
              "      <td>0.066723</td>\n",
              "      <td>-0.002044</td>\n",
              "      <td>0.107142</td>\n",
              "      <td>0.054817</td>\n",
              "      <td>-0.056148</td>\n",
              "      <td>0.120138</td>\n",
              "      <td>0.049171</td>\n",
              "      <td>0.061153</td>\n",
              "      <td>-0.010331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>421</td>\n",
              "      <td>0.048729</td>\n",
              "      <td>0.052783</td>\n",
              "      <td>0.118872</td>\n",
              "      <td>0.062439</td>\n",
              "      <td>-0.001681</td>\n",
              "      <td>0.104430</td>\n",
              "      <td>0.065293</td>\n",
              "      <td>-0.040294</td>\n",
              "      <td>0.011413</td>\n",
              "      <td>0.053153</td>\n",
              "      <td>0.043004</td>\n",
              "      <td>-0.034737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>818</td>\n",
              "      <td>0.055348</td>\n",
              "      <td>0.052168</td>\n",
              "      <td>0.106835</td>\n",
              "      <td>0.062273</td>\n",
              "      <td>-0.000939</td>\n",
              "      <td>0.104132</td>\n",
              "      <td>0.077789</td>\n",
              "      <td>-0.045932</td>\n",
              "      <td>0.051581</td>\n",
              "      <td>0.063339</td>\n",
              "      <td>0.038163</td>\n",
              "      <td>-0.029083</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>849 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ca816e4-79c4-4d71-af4b-0f538f18b7be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2ca816e4-79c4-4d71-af4b-0f538f18b7be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2ca816e4-79c4-4d71-af4b-0f538f18b7be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       ID  FINGER_POS_1  FINGER_POS_2  FINGER_POS_3  FINGER_POS_4  \\\n",
              "0     146      0.049949      0.052382      0.120513      0.055146   \n",
              "1    1474      0.044438      0.053474      0.120828      0.037784   \n",
              "2     190      0.049199      0.052962      0.122678      0.082618   \n",
              "3    1544      0.047385      0.053092      0.112071      0.061520   \n",
              "4     952      0.057916      0.051814      0.110039      0.077338   \n",
              "..    ...           ...           ...           ...           ...   \n",
              "844  2647      0.045396      0.054515      0.125953      0.070016   \n",
              "845  3970      0.045581      0.053086      0.121230      0.074780   \n",
              "846  1597      0.053151      0.053440      0.120700      0.066723   \n",
              "847   421      0.048729      0.052783      0.118872      0.062439   \n",
              "848   818      0.055348      0.052168      0.106835      0.062273   \n",
              "\n",
              "     FINGER_POS_5  FINGER_POS_6  FINGER_POS_7  FINGER_POS_8  FINGER_POS_9  \\\n",
              "0        0.000273      0.116482      0.067199     -0.053297      0.102544   \n",
              "1       -0.000080      0.125113      0.037577     -0.056280      0.128869   \n",
              "2       -0.002069      0.094010      0.045188     -0.040969     -0.017099   \n",
              "3       -0.001804      0.101508      0.073931     -0.052448      0.097279   \n",
              "4       -0.001631      0.095259      0.089907     -0.040567      0.027763   \n",
              "..            ...           ...           ...           ...           ...   \n",
              "844     -0.002723      0.098490      0.075598     -0.044305      0.039550   \n",
              "845      0.000851      0.092464      0.070901     -0.046276      0.032689   \n",
              "846     -0.002044      0.107142      0.054817     -0.056148      0.120138   \n",
              "847     -0.001681      0.104430      0.065293     -0.040294      0.011413   \n",
              "848     -0.000939      0.104132      0.077789     -0.045932      0.051581   \n",
              "\n",
              "     FINGER_POS_10  FINGER_POS_11  FINGER_POS_12  \n",
              "0         0.050549       0.032086      -0.044161  \n",
              "1         0.053176       0.042141      -0.036849  \n",
              "2         0.060214       0.038496      -0.039771  \n",
              "3         0.048981       0.050606      -0.026215  \n",
              "4         0.058488       0.052136      -0.021543  \n",
              "..             ...            ...            ...  \n",
              "844       0.051826       0.040719      -0.028590  \n",
              "845       0.056352       0.036889      -0.048131  \n",
              "846       0.049171       0.061153      -0.010331  \n",
              "847       0.053153       0.043004      -0.034737  \n",
              "848       0.063339       0.038163      -0.029083  \n",
              "\n",
              "[849 rows x 13 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "0aceed28e31bdb2de643565d9efcb60d1f00a1255bbdd312be5ef8641fc2c11d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
